<!DOCTYPE html>
<html>
<head>
    <title>Daily arXiv Subscriptions</title>
    <style>
        body { font-family: Arial, sans-serif; }
        h1 { color: #333; }
        .paper { margin-bottom: 20px; }
    </style>
</head>
<body>
    <h1>Daily arXiv Subscriptions</h1>
    
    <div class="paper">
        <h2><a href="http://arxiv.org/abs/2502.14866v1">LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention</a></h2>
        <p><strong>Time:</strong> 2025-02-20</p>
        <p><strong>Authors:</strong> Shang Yang, Junxian Guo, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han</p>
        <p><strong>Abstract:</strong> LServe is an efficient system that accelerates long-context LLM serving via hybrid sparse attention, combining static and dynamic sparsity patterns to skip computations on less important tokens block-wise and dynamically prune KV pages with a hierarchical query-centric policy, achieving up to 2.9x prefilling and 1.3-2.1x decoding speedups over vLLM while maintaining accuracy.</p>
    </div>
    
    <div class="paper">
        <h2><a href="http://arxiv.org/abs/2502.14864v1">Benchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework</a></h2>
        <p><strong>Time:</strong> 2025-02-20</p>
        <p><strong>Authors:</strong> Yuming Yang, Jiang Zhong, Li Jin, Jingwang Huang, Jingpeng Gao, Qing Liu, Yang Bai, Jingyuan Zhang, Rui Jiang, Kaiwen Wei</p>
        <p><strong>Abstract:</strong> The authors introduce Chart-based Multimodal Retrieval-Augmented Generation (MRAG) and propose CHARGE, a framework for generating high-quality evaluation data, to construct the Chart-MRAG Bench benchmark, which reveals critical limitations in current methods—including poor performance in chart-based scenarios, low accuracy even with ideal retrieval, and a text-over-visual bias in multimodal models.</p>
    </div>
    
    <div class="paper">
        <h2><a href="http://arxiv.org/abs/2502.14862v1">Interpretable Text Embeddings and Text Similarity Explanation: A Primer</a></h2>
        <p><strong>Time:</strong> 2025-02-20</p>
        <p><strong>Authors:</strong> Juri Opitz, Lucas Möller, Andrianos Michail, Simon Clematide</p>
        <p><strong>Abstract:</strong> This paper reviews emerging interpretability methods for explaining similarity scores in text embeddings, evaluating their techniques and potential to enhance transparency in AI and NLP systems.</p>
    </div>
    
</body>
</html>