<!DOCTYPE html>
<html>
<head>
    <title>Daily arXiv Subscriptions</title>
    <style>
        body { font-family: Arial, sans-serif; }
        h1 { color: #333; }
        .paper { margin-bottom: 20px; }
    </style>
</head>
<body>
    <h1>Daily arXiv Subscriptions</h1>
    
    <div class="paper">
        <h2><a href="http://arxiv.org/abs/2502.14866v1">LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention</a></h2>
        <p><strong>Time:</strong> 2025-02-20</p>
        <p><strong>Authors:</strong> Shang Yang, Junxian Guo, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han</p>
        <p><strong>Abstract:</strong> LServe, an efficient system for long-context LLM serving, combines hybrid sparse attention (using static and dynamic sparsity to skip less important tokens) with hierarchical KV page pruning, accelerating prefilling by up to 2.9x and decoding by 1.3-2.1x over vLLM while preserving accuracy.</p>
    </div>
    
    <div class="paper">
        <h2><a href="http://arxiv.org/abs/2502.14864v1">Benchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework</a></h2>
        <p><strong>Time:</strong> 2025-02-20</p>
        <p><strong>Authors:</strong> Yuming Yang, Jiang Zhong, Li Jin, Jingwang Huang, Jingpeng Gao, Qing Liu, Yang Bai, Jingyuan Zhang, Rui Jiang, Kaiwen Wei</p>
        <p><strong>Abstract:</strong> This paper introduces Chart-based Multimodal Retrieval-Augmented Generation (MRAG) and the CHARGE framework to generate high-quality evaluation data, constructs the Chart-MRAG Bench benchmark with 4,738 question-answering pairs from real-world documents, and identifies critical limitations in current methods—including poor retrieval performance, low accuracy (58.19%) and coverage (73.87%) even with ground-truth data, and text-over-visual bias in multimodal large language models (MLLMs)—releasing resources to address these challenges.</p>
    </div>
    
    <div class="paper">
        <h2><a href="http://arxiv.org/abs/2502.14862v1">Interpretable Text Embeddings and Text Similarity Explanation: A Primer</a></h2>
        <p><strong>Time:</strong> 2025-02-20</p>
        <p><strong>Authors:</strong> Juri Opitz, Lucas Möller, Andrianos Michail, Simon Clematide</p>
        <p><strong>Abstract:</strong> This paper provides a structured overview and evaluation of emerging interpretability methods designed to explain similarity scores in text embeddings, addressing transparency challenges crucial for AI and NLP systems like search.</p>
    </div>
    
</body>
</html>